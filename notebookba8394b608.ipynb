{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-13T11:27:38.777910Z",
     "iopub.status.busy": "2022-12-13T11:27:38.777535Z",
     "iopub.status.idle": "2022-12-13T11:27:38.785607Z",
     "shell.execute_reply": "2022-12-13T11:27:38.784662Z",
     "shell.execute_reply.started": "2022-12-13T11:27:38.777877Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install transformers\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_models as tfm\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.width\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:21:08.241364Z",
     "iopub.status.busy": "2022-12-13T11:21:08.240939Z",
     "iopub.status.idle": "2022-12-13T11:21:09.112704Z",
     "shell.execute_reply": "2022-12-13T11:21:09.110693Z",
     "shell.execute_reply.started": "2022-12-13T11:21:08.241327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144288</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>if I'm not sure what college I want to attend...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144289</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>seeking multiple opinions before making a har...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144290</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>it is better to seek multiple opinions instead...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144291</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>The impact of asking people to help you make a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144292</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>there are many other reasons one might want to...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144293 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end                                     discourse_text        discourse_type      discourse_type_num                                   predictionstring\n",
       "0       423A1CA112E2  1.622628e+12              8.0          229.0  Modern humans today are always on their phone....                  Lead                  Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n",
       "1       423A1CA112E2  1.622628e+12            230.0          312.0  They are some really bad consequences when stu...              Position              Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59\n",
       "2       423A1CA112E2  1.622628e+12            313.0          401.0  Some certain areas in the United States ban ph...              Evidence              Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n",
       "3       423A1CA112E2  1.622628e+12            402.0          758.0  When people have phones, they know about certa...              Evidence              Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...\n",
       "4       423A1CA112E2  1.622628e+12            759.0          886.0  Driving is one of the way how to get around. P...                 Claim                 Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...\n",
       "...              ...           ...              ...            ...                                                ...                   ...                     ...                                                ...\n",
       "144288  4C471936CD75  1.618153e+12           2234.0         3203.0   if I'm not sure what college I want to attend...              Evidence              Evidence 2  386 387 388 389 390 391 392 393 394 395 396 39...\n",
       "144289  4C471936CD75  1.618153e+12           3221.0         4509.0   seeking multiple opinions before making a har...              Evidence              Evidence 3  576 577 578 579 580 581 582 583 584 585 586 58...\n",
       "144290  4C471936CD75  1.618025e+12           4510.0         4570.0  it is better to seek multiple opinions instead...              Position              Position 1        828 829 830 831 832 833 834 835 836 837 838\n",
       "144291  4C471936CD75  1.618025e+12           4570.0         4922.0  The impact of asking people to help you make a...              Evidence              Evidence 4  839 840 841 842 843 844 845 846 847 848 849 85...\n",
       "144292  4C471936CD75  1.618025e+12           4935.0         5825.0  there are many other reasons one might want to...  Concluding Statement  Concluding Statement 1  905 906 907 908 909 910 911 912 913 914 915 91...\n",
       "\n",
       "[144293 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv('train.csv')\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:21:23.776994Z",
     "iopub.status.busy": "2022-12-13T11:21:23.776592Z",
     "iopub.status.idle": "2022-12-13T11:21:23.814804Z",
     "shell.execute_reply": "2022-12-13T11:21:23.813213Z",
     "shell.execute_reply.started": "2022-12-13T11:21:23.776958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144288</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>if I'm not sure what college I want to attend...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144289</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>seeking multiple opinions before making a har...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144290</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>it is better to seek multiple opinions instead...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144291</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>The impact of asking people to help you make a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144292</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>there are many other reasons one might want to...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144293 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end                                     discourse_text        discourse_type      discourse_type_num                                   predictionstring  labels\n",
       "0       423A1CA112E2  1.622628e+12              8.0          229.0  Modern humans today are always on their phone....                  Lead                  Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...       4\n",
       "1       423A1CA112E2  1.622628e+12            230.0          312.0  They are some really bad consequences when stu...              Position              Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59       5\n",
       "2       423A1CA112E2  1.622628e+12            313.0          401.0  Some certain areas in the United States ban ph...              Evidence              Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75       3\n",
       "3       423A1CA112E2  1.622628e+12            402.0          758.0  When people have phones, they know about certa...              Evidence              Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...       3\n",
       "4       423A1CA112E2  1.622628e+12            759.0          886.0  Driving is one of the way how to get around. P...                 Claim                 Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...       0\n",
       "...              ...           ...              ...            ...                                                ...                   ...                     ...                                                ...     ...\n",
       "144288  4C471936CD75  1.618153e+12           2234.0         3203.0   if I'm not sure what college I want to attend...              Evidence              Evidence 2  386 387 388 389 390 391 392 393 394 395 396 39...       3\n",
       "144289  4C471936CD75  1.618153e+12           3221.0         4509.0   seeking multiple opinions before making a har...              Evidence              Evidence 3  576 577 578 579 580 581 582 583 584 585 586 58...       3\n",
       "144290  4C471936CD75  1.618025e+12           4510.0         4570.0  it is better to seek multiple opinions instead...              Position              Position 1        828 829 830 831 832 833 834 835 836 837 838       5\n",
       "144291  4C471936CD75  1.618025e+12           4570.0         4922.0  The impact of asking people to help you make a...              Evidence              Evidence 4  839 840 841 842 843 844 845 846 847 848 849 85...       3\n",
       "144292  4C471936CD75  1.618025e+12           4935.0         5825.0  there are many other reasons one might want to...  Concluding Statement  Concluding Statement 1  905 906 907 908 909 910 911 912 913 914 915 91...       1\n",
       "\n",
       "[144293 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['Claim', 'Concluding Statement', 'Counterclaim', 'Evidence', 'Lead', 'Position', 'Rebuttal']\n",
    "traindf['labels'] = traindf.discourse_type.astype('category').cat.codes\n",
    "traindf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:21:45.492224Z",
     "iopub.status.busy": "2022-12-13T11:21:45.491808Z",
     "iopub.status.idle": "2022-12-13T11:21:45.497734Z",
     "shell.execute_reply": "2022-12-13T11:21:45.496166Z",
     "shell.execute_reply.started": "2022-12-13T11:21:45.492182Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = traindf['discourse_text'].values\n",
    "labels = traindf['labels'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:21:49.779967Z",
     "iopub.status.busy": "2022-12-13T11:21:49.779570Z",
     "iopub.status.idle": "2022-12-13T11:21:52.145624Z",
     "shell.execute_reply": "2022-12-13T11:21:52.144086Z",
     "shell.execute_reply.started": "2022-12-13T11:21:49.779934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving.\n",
      "Tokenized:  ['modern', 'humans', 'today', 'are', 'always', 'on', 'their', 'phone', '.', 'they', 'are', 'always', 'on', 'their', 'phone', 'more', 'than', '5', 'hours', 'a', 'day', 'no', 'stop', '.', 'all', 'they', 'do', 'is', 'text', 'back', 'and', 'forward', 'and', 'just', 'have', 'group', 'chat', '##s', 'on', 'social', 'media', '.', 'they', 'even', 'do', 'it', 'while', 'driving', '.']\n",
      "Token IDs:  [2715, 4286, 2651, 2024, 2467, 2006, 2037, 3042, 1012, 2027, 2024, 2467, 2006, 2037, 3042, 2062, 2084, 1019, 2847, 1037, 2154, 2053, 2644, 1012, 2035, 2027, 2079, 2003, 3793, 2067, 1998, 2830, 1998, 2074, 2031, 2177, 11834, 2015, 2006, 2591, 2865, 1012, 2027, 2130, 2079, 2009, 2096, 4439, 1012]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:02:03.974909Z",
     "iopub.status.busy": "2022-12-13T11:02:03.974512Z",
     "iopub.status.idle": "2022-12-13T11:05:25.133071Z",
     "shell.execute_reply": "2022-12-13T11:05:25.131424Z",
     "shell.execute_reply.started": "2022-12-13T11:02:03.974877Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▊                                                    | 4762/144293 [00:04<02:11, 1059.92it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████████████| 144293/144293 [02:28<00:00, 970.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving.\n",
      "Token IDs: [101, 2715, 4286, 2651, 2024, 2467, 2006, 2037, 3042, 1012, 2027, 2024, 2467, 2006, 2037, 3042, 2062, 2084, 1019, 2847, 1037, 2154, 2053, 2644, 1012, 2035, 2027, 2079, 2003, 3793, 2067, 1998, 2830, 1998, 2074, 2031, 2177, 11834, 2015, 2006, 2591, 2865, 1012, 2027, 2130, 2079, 2009, 2096, 4439, 1012, 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in tqdm.tqdm(sentences):\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "        # This function also supports truncation and conversion\n",
    "        # to pytorch tensors, but we need to do padding, so we\n",
    "        # can't use these features :( .\n",
    "#         max_length=512,          # Truncate all sentences.\n",
    "#         truncation=True\n",
    "        # return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.016937758588426\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "sent_len = pd.Series([len(i.split(' ')) for i in traindf['discourse_text']])\n",
    "print(sent_len.mean())\n",
    "print(sent_len.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pd.Series([len(i.split(' ')) for i in traindf['discourse_text']]).hist(bins = 150)\n",
    "sns.distplot(sent_len, kde=True, rug=True)\n",
    "plt.axvline(np.median(sent_len),color='b', linestyle='--')\n",
    "plt.axvline(np.mean(sent_len),color='green', linestyle='--')\n",
    "# plt.axvline(np.mode(sent_len),color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:05:32.295930Z",
     "iopub.status.busy": "2022-12-13T11:05:32.295558Z",
     "iopub.status.idle": "2022-12-13T11:05:32.329274Z",
     "shell.execute_reply": "2022-12-13T11:05:32.328100Z",
     "shell.execute_reply.started": "2022-12-13T11:05:32.295901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  913\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:06:54.809277Z",
     "iopub.status.busy": "2022-12-13T11:06:54.808915Z",
     "iopub.status.idle": "2022-12-13T11:06:55.612158Z",
     "shell.execute_reply": "2022-12-13T11:06:55.611066Z",
     "shell.execute_reply.started": "2022-12-13T11:06:54.809248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 50 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n",
      "[  101  2715  4286  2651  2024  2467  2006  2037  3042  1012  2027  2024\n",
      "  2467  2006  2037  3042  2062  2084  1019  2847  1037  2154  2053  2644\n",
      "  1012  2035  2027  2079  2003  3793  2067  1998  2830  1998  2074  2031\n",
      "  2177 11834  2015  2006  2591  2865  1012  2027  2130  2079  2009  2096\n",
      "  4439  1012]\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 47...\n",
    "MAX_LEN = 50\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')\n",
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:07:39.375330Z",
     "iopub.status.busy": "2022-12-13T11:07:39.374954Z",
     "iopub.status.idle": "2022-12-13T11:08:08.165558Z",
     "shell.execute_reply": "2022-12-13T11:08:08.164128Z",
     "shell.execute_reply.started": "2022-12-13T11:07:39.375297Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 144293/144293 [00:02<00:00, 49386.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in tqdm.tqdm(input_ids):\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:22:29.615586Z",
     "iopub.status.busy": "2022-12-13T11:22:29.615097Z",
     "iopub.status.idle": "2022-12-13T11:22:29.866193Z",
     "shell.execute_reply": "2022-12-13T11:22:29.864735Z",
     "shell.execute_reply.started": "2022-12-13T11:22:29.615547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n",
    "train_labels = to_categorical(list(train_labels))\n",
    "validation_labels = to_categorical(list(validation_labels))\n",
    "\n",
    "\n",
    "\n",
    "# train_labels.shape\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x236d20b5608>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAGdCAYAAAACMjetAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyX0lEQVR4nO3df3AUdZ7/8VcCJLBAfiCQIUtgYxn5IUpWfoQsnp5ninGBvY3iLUFqNwIrJZvkiMElZCFivqUGQqmASLK4V2LVyqK5K/AE5S4VBE6ZxRDkAPmhnih6Mol7kIxGCSHp7x8WvY7JJgF6Mj09z0dVap3pT3o+nV7Sr35/Pv1JhGEYhgAAANChyGB3AAAAwM4ISwAAAJ0gLAEAAHSCsAQAANAJwhIAAEAnCEsAAACdICwBAAB0grAEAADQid7B7oCdtbW16fPPP9fAgQMVERER7O4AAIBuMAxDX375pRITExUZee11IcJSJz7//HMlJSUFuxsAAOAqfPrppxo+fPg174ew1ImBAwdKkj459CPFDGDEEgCAUOD7qk0jb/3YvI5fK8JSJy4PvcUMiFTMwF5B7g2CxZ04PthdAABcgUtGi6SPLZtCQ1gCuvAfn/93sLsAALYTTjeShCUAQRdOv3QBhB7CEoCgo3oHwEq+L1sVf6N1+yMsAT2MKgoABNa3c5Y+smx/hCWgh1FFAYDAsrqyxPPwAAAAnaCyBACARRhmtweG4YAu8MsKAGAlwhIcxylzggh9AGAPhCXAppwS+sIJARdwJsISwhYXNgBAdxCWELao3ACAM7EoJYCQQfUOQDDwNByAkEH1DkAwUFkCAAAmKrjtUVkCAAAmu1dwnRDmCEsIW074BwwACDzCEsKW3e/GgO4g9AOBR1gCgBDmlNBP6IOdEZYAXDEubADCCWEJsCkCCQDYwxWHpX379mnNmjWqra3V2bNntW3bNmVmZkqSWlpatGLFCr3++uv66KOPFBsbq4yMDK1atUqJiYnmPs6dO6e8vDy99tprioyM1KxZs7Ru3ToNGDDAbHPkyBHl5OSopqZGQ4YMUV5enpYuXerXl8rKShUXF+vjjz9WSkqKVq9erenTp5vbDcPQypUr9fzzz6uhoUFTp05VeXm5UlJSrvSwYQOEBwBAMFxxWGpqatL48eM1f/583XvvvX7bvv76ax06dEjFxcUaP368zp8/r8WLF+sf//EfdfDgQbPd3LlzdfbsWVVVVamlpUXz5s3TwoULtWXLFkmSz+fTtGnTlJGRoYqKCh09elTz589XXFycFi5cKEnav3+/5syZo9LSUs2cOVNbtmxRZmamDh06pHHjxkmSysrKtH79er344otKTk5WcXGx3G63jh8/rr59+171Dw3B4ZS5GXZGIAWA9iIMwzCu+psjIvwqSx2pqanR5MmT9cknn2jEiBE6ceKExo4dq5qaGk2cOFGStGvXLk2fPl2fffaZEhMTVV5eruXLl8vr9SoqKkqStGzZMm3fvl0nT56UJM2ePVtNTU3asWOH+VlTpkxRamqqKioqZBiGEhMTtWTJEj3yyCOSpMbGRiUkJGjz5s3Kysrq8vh8Pp9iY2N1/v3rFTOw19X+mAAg6AjCCCeXjBbt0atqbGxUTEzMNe8v4HOWGhsbFRERobi4OEmSx+NRXFycGZQkKSMjQ5GRkTpw4IDuueceeTwe3X777WZQkiS3263Vq1fr/Pnzio+Pl8fjUUFBgd9nud1ubd++XZJ0+vRpeb1eZWRkmNtjY2OVlpYmj8fTYVhqbm5Wc3Oz+drn81nxIwCAgCEEAYEX0LB04cIFFRYWas6cOWay83q9Gjp0qH8nevfWoEGD5PV6zTbJycl+bRISEsxt8fHx8nq95nvfbfPdfXz3+zpq832lpaUqKSm5mkOFg3ExAoDwFrCw1NLSol/84hcyDEPl5eWB+hhLFRUV+VWrfD6fkpKSgtgj2AFzpQAgtITEH9K9HJQ++eQT7d6922+80OVyqb6+3q/9pUuXdO7cOblcLrNNXV2dX5vLr7tq893tl98bNmyYX5vU1NQO+x0dHa3o6OgrPVwAkEQVErAL2/8h3ctB6YMPPtCbb76p6667zm97enq6GhoaVFtbqwkTJkiSdu/erba2NqWlpZltli9frpaWFvXp00eSVFVVpVGjRik+Pt5sU11drfz8fHPfVVVVSk9PlyQlJyfL5XKpurraDEc+n08HDhzQokWLrD5swHJceAHAHq44LH311Vf68MMPzdenT5/W4cOHNWjQIA0bNkz33XefDh06pB07dqi1tdWcHzRo0CBFRUVpzJgxuvvuu/Xggw+qoqJCLS0tys3NVVZWlrkW0/3336+SkhItWLBAhYWFOnbsmNatW6dnnnnG/NzFixfrjjvu0FNPPaUZM2Zo69atOnjwoDZt2iTp2yf18vPz9fjjjyslJcVcOiAxMbHTp/cAu+jO8B+BCgAC74qXDtizZ4/uvPPOdu9nZ2frscceazcx+7I333xTf//3fy/p20Upc3Nz/RalXL9+/d9clHLw4MHKy8tTYWGh3z4rKyu1YsUKc1HKsrKyDhel3LRpkxoaGnTbbbdp48aNuvHG7g1ksnQAAIQmbiTCm9VLB1zTOktOF25hiV8uAAAnCLl1lhA6eOoLADrGzWR4IywBANAFbiZDS0gsHQCEAu4UAcCZbL90ABAquFMEAGeisgQAAILOztV5KksAHMfOv3QBgLCEK8aFDQAQTghLuGLM9ekYIRIAnImwBFiEEAkA9sAEbwBAwFAhhRMwwRvoAr/sAQBWIizBcaweDiN8AUB4IywBXWAuEgCEFuYsAUCIo1oJBBZzlgAgxFGtRHcQqu2DsISQwS8OAEAwEJYQMrgbBwKPmxKgPcISABMXSgBoj7AEwET1DoAT8DQc0AWqIwAQ3ngaDugC1REACG9UlgCLUIECAGeisgRYxAkVKAIfAAQeYQkIYU4IfE5CeAWcibAEIGAIDwCcgLAEIGC6W/kiVAGwM8ISgKBjOBGAlXgaDgB6GJUvILRY/TRcpGV7AgAAcCAqSwAChooMACcgLAEIGOYiAQgG5iwBAByHKiSsxAreAADHoQoJK1ldWWKCNwAAQCeoLAEAgKCzciiWYTgAAOA4Vg7FMsEbAIAuMGE8vFFZAoAexoUXCG+EJcAiXFABwJkIS4BFePQZgBNw49ceYQkAAJiccOPHOksAAAA9iLAEAADQCYbhEHSMjwMArMTSAXAcJ4yPAwDsI+iLUu7bt09r1qxRbW2tzp49q23btikzM9PcbhiGVq5cqeeff14NDQ2aOnWqysvLlZKSYrY5d+6c8vLy9NprrykyMlKzZs3SunXrNGDAALPNkSNHlJOTo5qaGg0ZMkR5eXlaunSpX18qKytVXFysjz/+WCkpKVq9erWmT59+RX3BX1HhAQA4QdArS01NTRo/frzmz5+ve++9t932srIyrV+/Xi+++KKSk5NVXFwst9ut48ePq2/fvpKkuXPn6uzZs6qqqlJLS4vmzZunhQsXasuWLZIkn8+nadOmKSMjQxUVFTp69Kjmz5+vuLg4LVy4UJK0f/9+zZkzR6WlpZo5c6a2bNmizMxMHTp0SOPGjet2X/BXVHgAAE5gdWUpwjAM46q/OSLCr7JkGIYSExO1ZMkSPfLII5KkxsZGJSQkaPPmzcrKytKJEyc0duxY1dTUaOLEiZKkXbt2afr06frss8+UmJio8vJyLV++XF6vV1FRUZKkZcuWafv27Tp58qQkafbs2WpqatKOHTvM/kyZMkWpqamqqKjoVl+64vP5FBsbq/PvX6+Ygb2u9scEAAB60Ldh6SM1NjYqJibmmvdn6Zyl06dPy+v1KiMjw3wvNjZWaWlp8ng8ysrKksfjUVxcnBmUJCkjI0ORkZE6cOCA7rnnHnk8Ht1+++1mUJIkt9ut1atX6/z584qPj5fH41FBQYHf57vdbm3fvr3bfQHsjGFRALg6QR+G64zX65UkJSQk+L2fkJBgbvN6vRo6dKh/J3r31qBBg/zaJCcnt9vH5W3x8fHyer1dfk5Xffm+5uZmNTc3m699Pl8XR4xQRhgBAHQHT8N9R2lpqUpKSoLdDfQQ5mgBgDPZegVvl8slSaqrq/N7v66uztzmcrlUX1/vt/3SpUs6d+6cX5uO9vHdz/hbbb67vau+fF9RUZEaGxvNr08//bQbRw0AAJzM0spScnKyXC6XqqurlZqaKunboawDBw5o0aJFkqT09HQ1NDSotrZWEyZMkCTt3r1bbW1tSktLM9ssX75cLS0t6tOnjySpqqpKo0aNUnx8vNmmurpa+fn55udXVVUpPT292335vujoaEVHR1v5IwEQBAyxAuEt6HOWvvrqK3344Yfm69OnT+vw4cMaNGiQRowYofz8fD3++ONKSUkxH9dPTEw0n5gbM2aM7r77bj344IOqqKhQS0uLcnNzlZWVpcTEREnS/fffr5KSEi1YsECFhYU6duyY1q1bp2eeecb83MWLF+uOO+7QU089pRkzZmjr1q06ePCgNm3aJOnbJ/W66gsAZ2KIFQhvQV86YM+ePbrzzjvbvZ+dna3NmzebC0Fu2rRJDQ0Nuu2227Rx40bdeONfe33u3Dnl5ub6LUq5fv36v7ko5eDBg5WXl6fCwkK/z6ysrNSKFSvMRSnLyso6XJSys750hqUDAAAIPVYvHXBN6yw5HWEJAIDQY3VYsnSCNwAAgNMQlgAAADpBWAIAAOgEi1ICAGARlq2wh6AvHQAA4YYLIBDeCEsAAoaQAcAJCEsAAobFIa8NYROwB8ISYFNcKAHAHghLgE1RlQGAq2P1nzth6QAAAIBOUFkCAAAmJ0wBYOkAAABgckK4sTvCEgAAIYz5je0xZwkAAKAHUVkCwgBlegDhhDlLAK5YsMr0hDQATkBYAhAwzKUAEAzMWQIAAOhBVJYAhC2GCQFnYs4SAFiEYULAmRiGAwAA6EFUlgAAQMjozvA5w3AAACBsdWf43OphOMIS0AUmAQNAaKGyBPQwJgEDCAZu1OyDsAQAMHGBBtojLAEATFRS4QTMWQIQtqh6AOgO5iwBCFtUPQB0B5UlAAFD5QaAE1BZAhAwVlduCF8AnICwBCBg7D5sRpgD0B2EJcAiXHgBwJkIS4BFGMICAGciLAE2ZfchLFw9gjAQWghLANDDCMJAYLF0AABYhAoP4EwsHYCg4wIDAAgnhCVcMYYQAAB2ZvUwXKR1uwIAAHAeKksAEAYYPkc4Yc4SAPQwggYQ3ghLANAF5ukBoYWlA4AwQTUDAK4Ow3BAmKCaAQBXh8oSEOKoGAFAYNm+stTa2qrHHntMf/zjH+X1epWYmKgHHnhAK1asUEREhCTJMAytXLlSzz//vBoaGjR16lSVl5crJSXF3M+5c+eUl5en1157TZGRkZo1a5bWrVunAQMGmG2OHDminJwc1dTUaMiQIcrLy9PSpUv9+lNZWani4mJ9/PHHSklJ0erVqzV9+nSrDxvoNipGABBYtl9nafXq1SovL9eGDRt04sQJrV69WmVlZXr22WfNNmVlZVq/fr0qKip04MAB9e/fX263WxcuXDDbzJ07V++9956qqqq0Y8cO7du3TwsXLjS3+3w+TZs2TSNHjlRtba3WrFmjxx57TJs2bTLb7N+/X3PmzNGCBQv07rvvKjMzU5mZmTp27JjVhw0AABwqwjAMw8odzpw5UwkJCfqXf/kX871Zs2apX79++uMf/yjDMJSYmKglS5bokUcekSQ1NjYqISFBmzdvVlZWlk6cOKGxY8eqpqZGEydOlCTt2rVL06dP12effabExESVl5dr+fLl8nq9ioqKkiQtW7ZM27dv18mTJyVJs2fPVlNTk3bs2GH2ZcqUKUpNTVVFRUWXx+Lz+RQbG6vz71+vmIG9LPsZwR4YDgMAZ7pktGiPXlVjY6NiYmKueX+WD8P95Cc/0aZNm/T+++/rxhtv1H//93/rrbfe0tNPPy1JOn36tLxerzIyMszviY2NVVpamjwej7KysuTxeBQXF2cGJUnKyMhQZGSkDhw4oHvuuUcej0e33367GZQkye12a/Xq1Tp//rzi4+Pl8XhUUFDg1z+3263t27dbfdgIQQyHAYAz2X6C97Jly+Tz+TR69Gj16tVLra2teuKJJzR37lxJktfrlSQlJCT4fV9CQoK5zev1aujQof4d7d1bgwYN8muTnJzcbh+Xt8XHx8vr9Xb6Od/X3Nys5uZm87XP57uiYwcAAM5jeVh65ZVX9NJLL2nLli266aabdPjwYeXn5ysxMVHZ2dlWf5ylSktLVVJSEuxuAAAcjmkAgWX7p+F++9vfatmyZcrKypIk3Xzzzfrkk09UWlqq7OxsuVwuSVJdXZ2GDRtmfl9dXZ1SU1MlSS6XS/X19X77vXTpks6dO2d+v8vlUl1dnV+by6+7anN5+/cVFRX5Ddv5fD4lJSVd0fEDANAVpgEElu2fhvv6668VGem/2169eqmtrU2SlJycLJfLperqanO7z+fTgQMHlJ6eLklKT09XQ0ODamtrzTa7d+9WW1ub0tLSzDb79u1TS0uL2aaqqkqjRo1SfHy82ea7n3O5zeXP+b7o6GjFxMT4fQEAgPBmeWXpZz/7mZ544gmNGDFCN910k9599109/fTTmj9/viQpIiJC+fn5evzxx5WSkqLk5GQVFxcrMTFRmZmZkqQxY8bo7rvv1oMPPqiKigq1tLQoNzdXWVlZSkxMlCTdf//9Kikp0YIFC1RYWKhjx45p3bp1euaZZ8y+LF68WHfccYeeeuopzZgxQ1u3btXBgwf9lhcAAKswtALYg9XDcJYvHfDll1+quLhY27ZtU319vRITEzVnzhw9+uij5pNrlxel3LRpkxoaGnTbbbdp48aNuvHGv9bMzp07p9zcXL9FKdevX/83F6UcPHiw8vLyVFhY6NefyspKrVixwlyUsqysrNuLUrJ0AAAAoefbYbiPLFs6wPKw5CSEJQAAQo/VYYm/DQfHYSgEAMKb7Z+GA4KNp0wAILzZ/mk4AAAAJyEsAQAAdIJhOKALzIECgNDCnCWghzEHCgBCi+3/kC4AwBpUNYGrQ2UJAMIEVU3g6vA0HAAAQA8iLAEAAHSCYTgAgOMw3yu8MWcJAIAuMN8rvPE0HIArxl02gHBCZQnAFeMuG0A44Wk4AACAHkRYAgAA6ATDcIBFmBcEAPbAnCXAppgXBAD2wNNwQBeo8ABAeKOyBHSBCg8AhDeehgMAAOhBVJYAwCIMAQP2wDAcgIDhYg8A7RGWAJsiuACAPRCWwgAXXQAArh5hKQzwdBgAIJzwNBwAAEAPorIEhAGGYgGEE56GA3DFGIoFegY3Js5EWAIAwCLcmNgDfxsOABB0VFBgZwzDAbhiXNgA4OoRlgCbIuAAgD0QlgCbYu4Dwgk3B7AzwhIAIOi4OYCVmOANAF2gSgGENyZ4A0AXqFIA4Y0/dwIAANCDqCwBCBkMrwHoDobhAIQthtcAdAcTvAEA6GFUNUMLlSUAQMAQCoD2CEsAABNDnXAChuEAoAtUR4DwxjAcAHSB6ggQ3lhnCQAAoAcFpLL0v//7vyosLNQbb7yhr7/+WjfccINeeOEFTZw4UZJkGIZWrlyp559/Xg0NDZo6darKy8uVkpJi7uPcuXPKy8vTa6+9psjISM2aNUvr1q3TgAEDzDZHjhxRTk6OampqNGTIEOXl5Wnp0qV+famsrFRxcbE+/vhjpaSkaPXq1Zo+fXogDhuwLYalAIQT2w/DnT9/XlOnTtWdd96pN954Q0OGDNEHH3yg+Ph4s01ZWZnWr1+vF198UcnJySouLpbb7dbx48fVt29fSdLcuXN19uxZVVVVqaWlRfPmzdPChQu1ZcsWSZLP59O0adOUkZGhiooKHT16VPPnz1dcXJwWLlwoSdq/f7/mzJmj0tJSzZw5U1u2bFFmZqYOHTqkcePGWX3ogG2F27AU4RCAlSIMwzCs3OGyZcv09ttv67/+67863G4YhhITE7VkyRI98sgjkqTGxkYlJCRo8+bNysrK0okTJzR27FjV1NSY1ahdu3Zp+vTp+uyzz5SYmKjy8nItX75cXq9XUVFR5mdv375dJ0+elCTNnj1bTU1N2rFjh/n5U6ZMUWpqqioqKro8Fp/Pp9jYWJ1//3rFDOx1TT8XOB8XaACwh0tGi/boVTU2NiomJuaa92d5Zenf//3f5Xa79U//9E/au3evfvjDH+o3v/mNHnzwQUnS6dOn5fV6lZGRYX5PbGys0tLS5PF4lJWVJY/Ho7i4ODMoSVJGRoYiIyN14MAB3XPPPfJ4PLr99tvNoCRJbrdbq1ev1vnz5xUfHy+Px6OCggK//rndbm3fvt3qwwbCrnqD0EKYB66e5WHpo48+Unl5uQoKCvS73/1ONTU1+ud//mdFRUUpOztbXq9XkpSQkOD3fQkJCeY2r9eroUOH+ne0d28NGjTIr01ycnK7fVzeFh8fL6/X2+nnfF9zc7Oam5vN1z6f70oPHwBsye5hnjAHO7M8LLW1tWnixIl68sknJUk//vGPdezYMVVUVCg7O9vqj7NUaWmpSkpKgt0NAAg7dg9zCC22X5Ry2LBhGjt2rN97Y8aM0b/9279JklwulySprq5Ow4YNM9vU1dUpNTXVbFNfX++3j0uXLuncuXPm97tcLtXV1fm1ufy6qzaXt39fUVGR37Cdz+dTUlJS1wcNAECYsXM10PZPw02dOlWnTp3ye+/999/XyJEjJUnJyclyuVyqrq42w5HP59OBAwe0aNEiSVJ6eroaGhpUW1urCRMmSJJ2796ttrY2paWlmW2WL1+ulpYW9enTR5JUVVWlUaNGmU/epaenq7q6Wvn5+WZfqqqqlJ6e3mHfo6OjFR0dbc0PAgBsxM4XNsDuLH8arqamRj/5yU9UUlKiX/ziF3rnnXf04IMPatOmTZo7d64kafXq1Vq1apXf0gFHjhzxWzrgpz/9qerq6lRRUWEuHTBx4kRz6YDGxkaNGjVK06ZNU2FhoY4dO6b58+frmWee8Vs64I477tCqVas0Y8YMbd26VU8++WS3lw7gaTgAuDaENASD1U/DWR6WJGnHjh0qKirSBx98oOTkZBUUFJhPw0l/XZRy06ZNamho0G233aaNGzfqxhv/OsB47tw55ebm+i1KuX79+r+5KOXgwYOVl5enwsJCv75UVlZqxYoV5qKUZWVl3V6UkrCEcMOFDYAThERYcgrCEuyOcAMA7dl+nSUAPYcniADYnRNu6ghLABAGnHDBAoKFsAQgbBEgAHQHYQlA2GIYE3Am2y9KCcB+qKAACCe2X5QSgP10t4JCqAKA9ghLAEwMSwFwAquH4SKt2xUAAIDzUFkCQhjDZgDQHnOWAJicMmxG6ANgZ4QlAEHnlNAHwB6YswQAANCDqCwBXWCICABCC3OWgB7GEBHQHjcRCCeEJQDAFeMmAnbGnzsBgB5GFQUILQzDAUAPo4oChBYqSwCuGJURAOGEyhKAK0ZlBEA4YZ0lAACAHkRYAgAA6ARhCQAAoBOEJQAAgE4QlgAAADrB03AhjkfCAQDwx9IB8MMj4QAA+GNRSsCmqPIBgD1QWQJ6GCEIAMIbYQnoQneHOglVAOBMhCXAIswfAwB7YM4SAMBERRNojzlLAABTuFU0CYcIBsISACBkhFs4xNVhGA4AQhzVESCwGIYDgBBHdQQILCpLAAKGigcAJ6CyBCBgqHggWAjqsDPCUojjFwwAAIFFWApxVAIAwJm4GbYPwhIAADbEzfDVY4I3rhh3JwCAcMIEb1wx7k6ciyAMAIFHWAJCGEHYXgivgDMRlgDAIoRXwB6YswQAAMJWdyq4zFkCAABhqzsV3JCrLK1atUpFRUVavHix1q5dK0m6cOGClixZoq1bt6q5uVlut1sbN25UQkKC+X1nzpzRokWL9Oabb2rAgAHKzs5WaWmpevf+a5f37NmjgoICvffee0pKStKKFSv0wAMP+H3+c889pzVr1sjr9Wr8+PF69tlnNXny5EAfNsT8DQBAcIRUZammpka///3vdcstt/i9//DDD2vnzp2qrKxUbGyscnNzde+99+rtt9+WJLW2tmrGjBlyuVzav3+/zp49q1/96lfq06ePnnzySUnS6dOnNWPGDD300EN66aWXVF1drV//+tcaNmyY3G63JOnll19WQUGBKioqlJaWprVr18rtduvUqVMaOnRoIA8dYv4Gwg83CIAzRRiGYQRix1999ZVuvfVWbdy4UY8//rhSU1O1du1aNTY2asiQIdqyZYvuu+8+SdLJkyc1ZswYeTweTZkyRW+88YZmzpypzz//3Kw2VVRUqLCwUF988YWioqJUWFionTt36tixY+ZnZmVlqaGhQbt27ZIkpaWladKkSdqwYYMkqa2tTUlJScrLy9OyZcu6PAafz6fY2Fidf/96xQzsZfWPCA7DhRIA7OGS0aI9elWNjY2KiYm55v0FrLKUk5OjGTNmKCMjQ48//rj5fm1trVpaWpSRkWG+N3r0aI0YMcIMSx6PRzfffLPfsJzb7daiRYv03nvv6cc//rE8Ho/fPi63yc/PlyRdvHhRtbW1KioqMrdHRkYqIyNDHo+nwz43NzerubnZfO3z+a7pZ4DwQiUNAK6enW84AxKWtm7dqkOHDqmmpqbdNq/Xq6ioKMXFxfm9n5CQIK/Xa7b5blC6vP3yts7a+Hw+ffPNNzp//rxaW1s7bHPy5MkO+11aWqqSkpLuHygAALCElTectp/g/emnn2rx4sWqqqpS3759rd59QBUVFamgoMB87fP5lJSUFMQeAXAiO99BA05g+wnetbW1qq+v16233mq+19raqn379mnDhg36j//4D128eFENDQ1+1aW6ujq5XC5Jksvl0jvvvOO337q6OnPb5f+9/N5328TExKhfv37q1auXevXq1WGby/v4vujoaEVHR1/dgYcRftEDAMKJ5WHprrvu0tGjR/3emzdvnkaPHq3CwkIlJSWpT58+qq6u1qxZsyRJp06d0pkzZ5Seni5JSk9P1xNPPKH6+nrzqbWqqirFxMRo7NixZpvXX3/d73OqqqrMfURFRWnChAmqrq5WZmampG8neFdXVys3N9fqww4rzM1BdxGsATiB5WFp4MCBGjdunN97/fv313XXXWe+v2DBAhUUFGjQoEGKiYlRXl6e0tPTNWXKFEnStGnTNHbsWP3yl79UWVmZvF6vVqxYoZycHLPy89BDD2nDhg1aunSp5s+fr927d+uVV17Rzp07zc8tKChQdna2Jk6cqMmTJ2vt2rVqamrSvHnzrD5sAB0gWAOBx01J4AVlBe9nnnlGkZGRmjVrlt+ilJf16tVLO3bs0KJFi5Senq7+/fsrOztb/+///T+zTXJysnbu3KmHH35Y69at0/Dhw/WHP/zBXGNJkmbPnq0vvvhCjz76qLxer1JTU7Vr1652k74RnvgFAwDojoCts+QErLMEAEDo+fZpuI/sv84SAIQbqpWAPdj+aTgACFfM0QLswep1liKt2xUAAIDzUFkCehhDNQAQWAzDASGOoRr7ILgC6A7CEoCw1d3gSqgCwhthCUDYIgQB6A7CEoKOCxYAwM4ISwg6u8/hIcwBQHgjLMFxCDcAACsRluA4dq9UAQACy+pFKQlLAACEMKrp7bHOEgB0gYsHACsRlgA4DkOx9kFwhRMQlgAAAUNwRTAwZwkhgztKAEAwMGcJISPc7igJhwDgTIQlwCLhFg4R3rg5QDghLAFACCO0AIFHWAJCGBdKAAg8whIchwABALASYQmOw9whIPC4KUE4ISwBYYALGwBcPcISEAaotl0bwiYQ3ghLAK4Y4QFAOCEswXG4kAMArERYguMw5ATYBzcvcALCEgAgYLh5QTDwh3QBAAFDJQhOwB/SBQCLEAwAdAdhCUDYYogIcCaG4QCLUFUAAGdiGA6wCFUFOAGhHwg8whIA9DACDhBaCEsAHIcwAsBKhCUAjhNOQ6wEQyDwCEsATFx4AaA9whIAUzhVZAA4F0sHALhiVIwAhBOWDgBwxagYAbBaON2EEZYAAMAVs/NNmNXDcJHW7QoAAMB5qCwBCFvhNIwAhBPmLMEPv+wBAAgswlKIs/OYMYCOcZMDhBbCEgD0MG5ygMCy/QTv0tJSTZo0SQMHDtTQoUOVmZmpU6dO+bW5cOGCcnJydN1112nAgAGaNWuW6urq/NqcOXNGM2bM0A9+8AMNHTpUv/3tb3Xp0iW/Nnv27NGtt96q6Oho3XDDDdq8eXO7/jz33HP60Y9+pL59+yotLU3vvPOO1YcMAAAczPLK0t69e5WTk6NJkybp0qVL+t3vfqdp06bp+PHj6t+/vyTp4Ycf1s6dO1VZWanY2Fjl5ubq3nvv1dtvvy1Jam1t1YwZM+RyubR//36dPXtWv/rVr9SnTx89+eSTkqTTp09rxowZeuihh/TSSy+purpav/71rzVs2DC53W5J0ssvv6yCggJVVFQoLS1Na9euldvt1qlTpzR06FCrDx0IeQwPAXACqyd4RxiGYVi2tw588cUXGjp0qPbu3avbb79djY2NGjJkiLZs2aL77rtPknTy5EmNGTNGHo9HU6ZM0RtvvKGZM2fq888/V0JCgiSpoqJChYWF+uKLLxQVFaXCwkLt3LlTx44dMz8rKytLDQ0N2rVrlyQpLS1NkyZN0oYNGyRJbW1tSkpKUl5enpYtW9Zl330+n2JjY3X+/esVM7CX1T8aAECI4EYitFwyWrRHr6qxsVExMTHXvL+Az1lqbGyUJA0aNEiSVFtbq5aWFmVkZJhtRo8erREjRphhyePx6OabbzaDkiS53W4tWrRI7733nn784x/L4/H47eNym/z8fEnSxYsXVVtbq6KiInN7ZGSkMjIy5PF4Ouxrc3Ozmpubzdc+n+/aDh4AAoyLOBB4AQ1LbW1tys/P19SpUzVu3DhJktfrVVRUlOLi4vzaJiQkyOv1mm2+G5Qub7+8rbM2Pp9P33zzjc6fP6/W1tYO25w8ebLD/paWlqqkpOTqDhZA2CO4AM4U0LCUk5OjY8eO6a233grkx1imqKhIBQUF5mufz6ekpKQg9gjhjAsvANhDwMJSbm6uduzYoX379mn48OHm+y6XSxcvXlRDQ4Nfdamurk4ul8ts8/2n1i4/LffdNt9/gq6urk4xMTHq16+fevXqpV69enXY5vI+vi86OlrR0dFXd8Boh4s9AMAJLA9LhmEoLy9P27Zt0549e5ScnOy3fcKECerTp4+qq6s1a9YsSdKpU6d05swZpaenS5LS09P1xBNPqL6+3nxqraqqSjExMRo7dqzZ5vXXX/fbd1VVlbmPqKgoTZgwQdXV1crMzJT07bBgdXW1cnNzrT5sdIC1ZICOcSMBhBbLw1JOTo62bNmiV199VQMHDjTnGMXGxqpfv36KjY3VggULVFBQoEGDBikmJkZ5eXlKT0/XlClTJEnTpk3T2LFj9ctf/lJlZWXyer1asWKFcnJyzMrPQw89pA0bNmjp0qWaP3++du/erVdeeUU7d+40+1JQUKDs7GxNnDhRkydP1tq1a9XU1KR58+ZZfdi4Blw4AAB2ZvnSARERER2+/8ILL+iBBx6Q9O2ilEuWLNGf/vQnNTc3y+12a+PGjX7DY5988okWLVqkPXv2qH///srOztaqVavUu/df892ePXv08MMP6/jx4xo+fLiKi4vNz7hsw4YNWrNmjbxer1JTU7V+/XqlpaV161hYOgAAYHfccLZn9dIBAV9nKZQRlgAACD3f/rmTj0JnnSWgp3GXBQDhzeoVvAlLcBwmlgPA1eOGsz3CEgAgZHAhRzAQlgAAIYPKMbrj2zlL1u2PsAQgYKgCAAgG5iwBFuFCDgDoDsISHIcQBACwEmEJjtPdOQ2EKgBAdxCWELaYKGofBFcAdhYZ7A4AAADYGZUlAEHnlCofFTLAmQhLAGARO4c+ghxw9QhLABAG7BzkAKuxKCUchzteAICVWJQSjsMdLwDASlSWAAAmKrNAe1SWACBMEIQAeyAsIWD4RQ8AcALCEgIm3OYiEQ4BwJkIS4BFnBAOCXwA0B5hCYDJCYEPAHgaDkDAUFkC4AQ8DQcgYIJVWSKkAbAzwhJgES74AOBMhCXAIsz3sQ+CKwArEZaALnDhBYDwRlgCukDFCABCC0/DAUAXqAYC4Y2n4QCgC1QDgfBmdWUp0rpdAQAAOA9hCQAAoBMMw4U45mYAAOCPOUvww9wMAAD88TQcgLBFJRVAd1BZAhC27F5JJcwBzkRYAgCL2D3MAeGCpQMAAAB6EJUlAMAVY8gRdsacJQDAFSPcAFePsASEAS6UAHD1CEtAGGDiMYBwwjpLAExUjACgPeYsATBRMQKuDTcc6A7CEsIWvyQBAN1BWELYoioDAM7EnCUAJqpjANAec5auwnPPPac1a9bI6/Vq/PjxevbZZzV58uRgdwu4ZlTHgI5xIwErOT4svfzyyyooKFBFRYXS0tK0du1aud1unTp1SkOHDg129wAAAcCNRHizehguwjAMw7rd2U9aWpomTZqkDRs2SJLa2tqUlJSkvLw8LVu2rNPv9fl8io2N1fn3r1fMwF490V0AgAWoLIW3S0aL9uhVNTY2KiYm5pr35+jK0sWLF1VbW6uioiLzvcjISGVkZMjj8bRr39zcrObmZvN1Y2OjJMn3VVvgOwsAsEzlqUPB7gKCyPdVm0beKllVD3J0WPrLX/6i1tZWJSQk+L2fkJCgkydPtmtfWlqqkpKSdu+PvPXjQHURAAAEyP/93/8pNjb2mvfj6LB0pYqKilRQUGC+bmho0MiRI3XmzBlLfti4Nj6fT0lJSfr0008tKavi6nEu7INzYR+cC/tobGzUiBEjNGjQIEv25+iwNHjwYPXq1Ut1dXV+79fV1cnlcrVrHx0drejo6Hbvx8bG8n98G4mJieF82ATnwj44F/bBubCPyMhIa/ZjyV5sKioqShMmTFB1dbX5Xltbm6qrq5Wenh7EngEAgFDh6MqSJBUUFCg7O1sTJ07U5MmTtXbtWjU1NWnevHnB7hoAAAgBjg9Ls2fP1hdffKFHH31UXq9Xqamp2rVrV7tJ3x2Jjo7WypUrOxyaQ8/jfNgH58I+OBf2wbmwD6vPhePXWQIAALgWjp6zBAAAcK0ISwAAAJ0gLAEAAHSCsAQAANAJwlInnnvuOf3oRz9S3759lZaWpnfeeSfYXXK8ffv26Wc/+5kSExMVERGh7du3+203DEOPPvqohg0bpn79+ikjI0MffPBBcDrrcKWlpZo0aZIGDhyooUOHKjMzU6dOnfJrc+HCBeXk5Oi6667TgAEDNGvWrHaLwOLalZeX65ZbbjEXO0xPT9cbb7xhbuc8BM+qVasUERGh/Px88z3OR8957LHHFBER4fc1evRoc7tV54Kw9De8/PLLKigo0MqVK3Xo0CGNHz9ebrdb9fX1we6aozU1NWn8+PF67rnnOtxeVlam9evXq6KiQgcOHFD//v3ldrt14cKFHu6p8+3du1c5OTn685//rKqqKrW0tGjatGlqamoy2zz88MN67bXXVFlZqb179+rzzz/XvffeG8ReO9Pw4cO1atUq1dbW6uDBg/qHf/gH/fznP9d7770nifMQLDU1Nfr973+vW265xe99zkfPuummm3T27Fnz66233jK3WXYuDHRo8uTJRk5Ojvm6tbXVSExMNEpLS4PYq/Aiydi2bZv5uq2tzXC5XMaaNWvM9xoaGozo6GjjT3/6UxB6GF7q6+sNScbevXsNw/j2Z9+nTx+jsrLSbHPixAlDkuHxeILVzbARHx9v/OEPf+A8BMmXX35ppKSkGFVVVcYdd9xhLF682DAM/l30tJUrVxrjx4/vcJuV54LKUgcuXryo2tpaZWRkmO9FRkYqIyNDHo8niD0Lb6dPn5bX6/U7L7GxsUpLS+O89IDGxkZJMv8wZW1trVpaWvzOx+jRozVixAjORwC1trZq69atampqUnp6OuchSHJycjRjxgy/n7vEv4tg+OCDD5SYmKjrr79ec+fO1ZkzZyRZey4cv4L31fjLX/6i1tbWdqt8JyQk6OTJk0HqFbxeryR1eF4ub0NgtLW1KT8/X1OnTtW4ceMkfXs+oqKiFBcX59eW8xEYR48eVXp6ui5cuKABAwZo27ZtGjt2rA4fPsx56GFbt27VoUOHVFNT024b/y56VlpamjZv3qxRo0bp7NmzKikp0d/93d/p2LFjlp4LwhKALuXk5OjYsWN+cwHQs0aNGqXDhw+rsbFR//qv/6rs7Gzt3bs32N0KO59++qkWL16sqqoq9e3bN9jdCXs//elPzf++5ZZblJaWppEjR+qVV15Rv379LPschuE6MHjwYPXq1avdjPm6ujq5XK4g9QqXf/acl56Vm5urHTt26M0339Tw4cPN910uly5evKiGhga/9pyPwIiKitINN9ygCRMmqLS0VOPHj9e6des4Dz2strZW9fX1uvXWW9W7d2/17t1be/fu1fr169W7d28lJCRwPoIoLi5ON954oz788ENL/20QljoQFRWlCRMmqLq62nyvra1N1dXVSk9PD2LPwltycrJcLpffefH5fDpw4ADnJQAMw1Bubq62bdum3bt3Kzk52W/7hAkT1KdPH7/zcerUKZ05c4bz0QPa2trU3NzMeehhd911l44eParDhw+bXxMnTtTcuXPN/+Z8BM9XX32l//mf/9GwYcOs/bdxDZPQHW3r1q1GdHS0sXnzZuP48ePGwoULjbi4OMPr9Qa7a4725ZdfGu+++67x7rvvGpKMp59+2nj33XeNTz75xDAMw1i1apURFxdnvPrqq8aRI0eMn//850ZycrLxzTffBLnnzrNo0SIjNjbW2LNnj3H27Fnz6+uvvzbbPPTQQ8aIESOM3bt3GwcPHjTS09ON9PT0IPbamZYtW2bs3bvXOH36tHHkyBFj2bJlRkREhPGf//mfhmFwHoLtu0/DGQbnoyctWbLE2LNnj3H69Gnj7bffNjIyMozBgwcb9fX1hmFYdy4IS5149tlnjREjRhhRUVHG5MmTjT//+c/B7pLjvfnmm4akdl/Z2dmGYXy7fEBxcbGRkJBgREdHG3fddZdx6tSp4HbaoTo6D5KMF154wWzzzTffGL/5zW+M+Ph44wc/+IFxzz33GGfPng1epx1q/vz5xsiRI42oqChjyJAhxl133WUGJcPgPATb98MS56PnzJ492xg2bJgRFRVl/PCHPzRmz55tfPjhh+Z2q85FhGEYhgWVLwAAAEdizhIAAEAnCEsAAACdICwBAAB0grAEAADQCcISAABAJwhLAAAAnSAsAQAAdIKwBAAA0AnCEgAAQCcISwAAAJ0gLAEAAHSCsAQAANCJ/w/YvcRxPk/EzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(train_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:22:35.553041Z",
     "iopub.status.busy": "2022-12-13T11:22:35.552644Z",
     "iopub.status.idle": "2022-12-13T11:22:39.704121Z",
     "shell.execute_reply": "2022-12-13T11:22:39.703070Z",
     "shell.execute_reply.started": "2022-12-13T11:22:35.553007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype\n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels, train_masks))\n",
    "valid = tf.data.Dataset.from_tensor_slices((validation_inputs, validation_labels, validation_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       " array([  101,  1045,  2572,  1999,  5684,  1997,  1996,  6092,  2267,\n",
       "         2138,  1997,  1996,  3056,  3012,  1997,  9560,  1998,  2022,\n",
       "        27199,  2063,  1997,  1996,  2163,  1012,   102,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0])>,\n",
       " <tf.Tensor: shape=(), dtype=int8, numpy=5>,\n",
       " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0])>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:22:49.587790Z",
     "iopub.status.busy": "2022-12-13T11:22:49.587347Z",
     "iopub.status.idle": "2022-12-13T11:22:49.596389Z",
     "shell.execute_reply": "2022-12-13T11:22:49.594365Z",
     "shell.execute_reply.started": "2022-12-13T11:22:49.587757Z"
    }
   },
   "outputs": [],
   "source": [
    "# #  The DataLoader needs to know our batch size for training, so we specify it\n",
    "# # here.\n",
    "# # For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# # 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# # Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# # Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  101,  4553,  2129,  ...,     0,     0,     0],\n",
       "         [  101,  2007,  2715,  ...,  4007,  1012,  2360],\n",
       "         [  101,  2009,  2003,  ...,  2051,  1012,   102],\n",
       "         ...,\n",
       "         [  101,  1996, 23025,  ...,  1012,  1999,  2060],\n",
       "         [  101,  2062,  5470,  ...,     0,     0,     0],\n",
       "         [  101,  1045,  5993,  ...,     0,     0,     0]], dtype=torch.int32),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.]])]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# bert_config_file = os.path.join(\"bert_config.json\")\n",
    "# config_dict = {'attention_probs_dropout_prob': 0.1,\n",
    "#  'hidden_act': 'gelu',\n",
    "#  'hidden_dropout_prob': 0.1,\n",
    "#  'hidden_size': 768,\n",
    "#  'initializer_range': 0.02,\n",
    "#  'intermediate_size': 3072,\n",
    "#  'max_position_embeddings': 512,\n",
    "#  'num_attention_heads': 12,\n",
    "#  'num_hidden_layers': 12,\n",
    "#  'type_vocab_size': 2,\n",
    "#  'vocab_size': 30522}\n",
    "# config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertConfig\n",
    "\n",
    "# config = BertConfig.from_pretrained(\"bert-base-cased\", num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TFBertForSequenceClassification\n",
    "\n",
    "# model = TFBertForSequenceClassification(config)\n",
    "# # config.num_labels = 7\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "# metrics = [tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model([[train., attention_mask]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train, validation_data=valid, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = torch.tensor([1]).unsqueeze(0)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:22:54.835266Z",
     "iopub.status.busy": "2022-12-13T11:22:54.834840Z",
     "iopub.status.idle": "2022-12-13T11:23:12.764773Z",
     "shell.execute_reply": "2022-12-13T11:23:12.762337Z",
     "shell.execute_reply.started": "2022-12-13T11:22:54.835211Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 7, # The number of output labels--7for Multi-class classification.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:25:32.450105Z",
     "iopub.status.busy": "2022-12-13T11:25:32.449744Z",
     "iopub.status.idle": "2022-12-13T11:25:32.459063Z",
     "shell.execute_reply": "2022-12-13T11:25:32.457571Z",
     "shell.execute_reply.started": "2022-12-13T11:25:32.450075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (7, 768)\n",
      "classifier.bias                                                 (7,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:25:42.600035Z",
     "iopub.status.busy": "2022-12-13T11:25:42.599638Z",
     "iopub.status.idle": "2022-12-13T11:25:42.612233Z",
     "shell.execute_reply": "2022-12-13T11:25:42.610732Z",
     "shell.execute_reply.started": "2022-12-13T11:25:42.600002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\python\\python37\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#  Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:28:54.792418Z",
     "iopub.status.busy": "2022-12-13T11:28:54.792045Z",
     "iopub.status.idle": "2022-12-13T11:28:54.801180Z",
     "shell.execute_reply": "2022-12-13T11:28:54.800249Z",
     "shell.execute_reply.started": "2022-12-13T11:28:54.792390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 1\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  1045,  2572,  1999,  5684,  1997,  1996,  6092,  2267,  2138,\n",
       "          1997,  1996,  3056,  3012,  1997,  9560,  1998,  2022, 27199,  2063,\n",
       "          1997,  1996,  2163,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        dtype=torch.int32),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T11:34:14.161246Z",
     "iopub.status.busy": "2022-12-13T11:34:14.160841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/4 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:05,  5.11s/it]\u001b[A\n",
      "2it [00:09,  5.03s/it]\u001b[A\n",
      "3it [00:14,  4.97s/it]\u001b[A\n",
      "4it [00:19,  4.93s/it]\u001b[A\n",
      "5it [00:24,  4.89s/it]\u001b[A\n",
      "6it [00:29,  4.94s/it]\u001b[A\n",
      "7it [00:34,  5.03s/it]\u001b[A\n",
      "8it [00:39,  5.10s/it]\u001b[A\n",
      "9it [00:45,  5.19s/it]\u001b[A\n",
      "10it [00:50,  5.19s/it]\u001b[A\n",
      "11it [00:55,  5.20s/it]\u001b[A\n",
      "12it [01:00,  5.20s/it]\u001b[A\n",
      "13it [01:06,  5.22s/it]\u001b[A\n",
      "14it [01:11,  5.20s/it]\u001b[A\n",
      "15it [01:16,  5.20s/it]\u001b[A\n",
      "16it [01:21,  5.21s/it]\u001b[A\n",
      "17it [01:27,  5.21s/it]\u001b[A\n",
      "18it [01:32,  5.21s/it]\u001b[A\n",
      "19it [01:37,  5.24s/it]\u001b[A\n",
      "20it [01:42,  5.24s/it]\u001b[A\n",
      "21it [01:48,  5.23s/it]\u001b[A\n",
      "22it [01:53,  5.24s/it]\u001b[A\n",
      "23it [01:58,  5.23s/it]\u001b[A\n",
      "24it [02:03,  5.26s/it]\u001b[A\n",
      "25it [02:09,  5.26s/it]\u001b[A\n",
      "26it [02:14,  5.27s/it]\u001b[A\n",
      "27it [02:19,  5.26s/it]\u001b[A\n",
      "28it [02:24,  5.27s/it]\u001b[A\n",
      "29it [02:30,  5.28s/it]\u001b[A\n",
      "30it [02:35,  5.25s/it]\u001b[A\n",
      "31it [02:40,  5.23s/it]\u001b[A\n",
      "32it [02:45,  5.25s/it]\u001b[A\n",
      "33it [02:51,  5.21s/it]\u001b[A\n",
      "34it [02:56,  5.22s/it]\u001b[A\n",
      "35it [03:01,  5.22s/it]\u001b[A\n",
      "36it [03:06,  5.20s/it]\u001b[A\n",
      "37it [03:11,  5.22s/it]\u001b[A\n",
      "38it [03:17,  5.21s/it]\u001b[A\n",
      "39it [03:22,  5.22s/it]\u001b[A\n",
      "40it [03:27,  5.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of  4,059.    Elapsed: 0:03:28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [03:32,  5.21s/it]\u001b[A\n",
      "42it [03:37,  5.22s/it]\u001b[A\n",
      "43it [03:43,  5.21s/it]\u001b[A\n",
      "44it [03:48,  5.18s/it]\u001b[A\n",
      "45it [03:53,  5.20s/it]\u001b[A\n",
      "46it [03:58,  5.21s/it]\u001b[A\n",
      "47it [04:04,  5.26s/it]\u001b[A\n",
      "48it [04:09,  5.35s/it]\u001b[A\n",
      "49it [04:14,  5.33s/it]\u001b[A\n",
      "50it [04:20,  5.27s/it]\u001b[A\n",
      "51it [04:25,  5.25s/it]\u001b[A\n",
      "52it [04:30,  5.27s/it]\u001b[A\n",
      "53it [04:36,  5.47s/it]\u001b[A\n",
      "54it [04:42,  5.56s/it]\u001b[A\n",
      "55it [04:47,  5.47s/it]\u001b[A\n",
      "56it [04:52,  5.41s/it]\u001b[A\n",
      "57it [04:58,  5.37s/it]\u001b[A\n",
      "58it [05:03,  5.32s/it]\u001b[A\n",
      "59it [05:08,  5.28s/it]\u001b[A\n",
      "60it [05:13,  5.27s/it]\u001b[A\n",
      "61it [05:19,  5.38s/it]\u001b[A\n",
      "62it [05:24,  5.34s/it]\u001b[A\n",
      "63it [05:29,  5.29s/it]\u001b[A\n",
      "64it [05:34,  5.26s/it]\u001b[A\n",
      "65it [05:40,  5.26s/it]\u001b[A\n",
      "66it [05:45,  5.23s/it]\u001b[A\n",
      "67it [05:50,  5.22s/it]\u001b[A\n",
      "68it [05:55,  5.21s/it]\u001b[A\n",
      "69it [06:01,  5.20s/it]\u001b[A\n",
      "70it [06:06,  5.22s/it]\u001b[A\n",
      "71it [06:11,  5.21s/it]\u001b[A\n",
      "72it [06:16,  5.20s/it]\u001b[A\n",
      "73it [06:21,  5.21s/it]\u001b[A\n",
      "74it [06:27,  5.22s/it]\u001b[A\n",
      "75it [06:32,  5.22s/it]\u001b[A\n",
      "76it [06:37,  5.23s/it]\u001b[A\n",
      "77it [06:42,  5.21s/it]\u001b[A\n",
      "78it [06:48,  5.23s/it]\u001b[A\n",
      "79it [06:53,  5.23s/it]\u001b[A\n",
      "80it [06:58,  5.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    80  of  4,059.    Elapsed: 0:06:59.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [07:03,  5.25s/it]\u001b[A\n",
      "82it [07:08,  5.24s/it]\u001b[A\n",
      "83it [07:14,  5.20s/it]\u001b[A\n",
      "84it [07:19,  5.19s/it]\u001b[A\n",
      "85it [07:24,  5.20s/it]\u001b[A\n",
      "86it [07:29,  5.18s/it]\u001b[A\n",
      "87it [07:34,  5.21s/it]\u001b[A\n",
      "88it [07:40,  5.22s/it]\u001b[A\n",
      "89it [07:45,  5.24s/it]\u001b[A\n",
      "90it [07:50,  5.26s/it]\u001b[A\n",
      "91it [07:56,  5.27s/it]\u001b[A\n",
      "92it [08:01,  5.25s/it]\u001b[A\n",
      "93it [08:06,  5.24s/it]\u001b[A\n",
      "94it [08:11,  5.26s/it]\u001b[A\n",
      "95it [08:16,  5.25s/it]\u001b[A\n",
      "96it [08:22,  5.24s/it]\u001b[A\n",
      "97it [08:27,  5.24s/it]\u001b[A\n",
      "98it [08:32,  5.22s/it]\u001b[A\n",
      "99it [08:37,  5.23s/it]\u001b[A\n",
      "100it [08:43,  5.21s/it]\u001b[A\n",
      "101it [08:48,  5.20s/it]\u001b[A\n",
      "102it [08:53,  5.20s/it]\u001b[A\n",
      "103it [08:58,  5.22s/it]\u001b[A\n",
      "104it [09:03,  5.25s/it]\u001b[A\n",
      "105it [09:09,  5.39s/it]\u001b[A\n",
      "106it [09:15,  5.36s/it]\u001b[A\n",
      "107it [09:20,  5.33s/it]\u001b[A\n",
      "108it [09:25,  5.30s/it]\u001b[A\n",
      "109it [09:30,  5.27s/it]\u001b[A\n",
      "110it [09:35,  5.26s/it]\u001b[A\n",
      "111it [09:41,  5.27s/it]\u001b[A\n",
      "112it [09:46,  5.24s/it]\u001b[A\n",
      "113it [09:51,  5.23s/it]\u001b[A\n",
      "114it [09:56,  5.24s/it]\u001b[A\n",
      "115it [10:02,  5.22s/it]\u001b[A\n",
      "116it [10:07,  5.21s/it]\u001b[A\n",
      "117it [10:12,  5.23s/it]\u001b[A\n",
      "118it [10:17,  5.22s/it]\u001b[A\n",
      "119it [10:22,  5.23s/it]\u001b[A\n",
      "120it [10:28,  5.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   120  of  4,059.    Elapsed: 0:10:28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "121it [10:33,  5.20s/it]\u001b[A\n",
      "122it [10:38,  5.21s/it]\u001b[A\n",
      "123it [10:43,  5.22s/it]\u001b[A\n",
      "124it [10:48,  5.22s/it]\u001b[A\n",
      "125it [10:54,  5.21s/it]\u001b[A\n",
      "126it [10:59,  5.22s/it]\u001b[A\n",
      "127it [11:04,  5.23s/it]\u001b[A\n",
      "128it [11:09,  5.22s/it]\u001b[A\n",
      "129it [11:15,  5.22s/it]\u001b[A\n",
      "130it [11:20,  5.20s/it]\u001b[A\n",
      "131it [11:25,  5.21s/it]\u001b[A\n",
      "132it [11:30,  5.23s/it]\u001b[A\n",
      "133it [11:35,  5.23s/it]\u001b[A\n",
      "134it [11:41,  5.21s/it]\u001b[A\n",
      "135it [11:46,  5.20s/it]\u001b[A\n",
      "136it [11:51,  5.21s/it]\u001b[A\n",
      "137it [11:56,  5.21s/it]\u001b[A\n",
      "138it [12:01,  5.21s/it]\u001b[A\n",
      "139it [12:07,  5.20s/it]\u001b[A\n",
      "140it [12:12,  5.22s/it]\u001b[A\n",
      "141it [12:17,  5.25s/it]\u001b[A\n",
      "142it [12:22,  5.22s/it]\u001b[A\n",
      "143it [12:28,  5.23s/it]\u001b[A\n",
      "144it [12:33,  5.24s/it]\u001b[A\n",
      "145it [12:38,  5.23s/it]\u001b[A\n",
      "146it [12:43,  5.27s/it]\u001b[A\n",
      "147it [12:49,  5.28s/it]\u001b[A\n",
      "148it [12:54,  5.26s/it]\u001b[A\n",
      "149it [12:59,  5.26s/it]\u001b[A\n",
      "150it [13:05,  5.26s/it]\u001b[A\n",
      "151it [13:10,  5.23s/it]\u001b[A\n",
      "152it [13:15,  5.24s/it]\u001b[A\n",
      "153it [13:20,  5.24s/it]\u001b[A\n",
      "154it [13:25,  5.23s/it]\u001b[A\n",
      "155it [13:31,  5.22s/it]\u001b[A\n",
      "156it [13:36,  5.21s/it]\u001b[A\n",
      "157it [13:41,  5.18s/it]\u001b[A\n",
      "158it [13:46,  5.18s/it]\u001b[A\n",
      "159it [13:51,  5.21s/it]\u001b[A\n",
      "160it [13:57,  5.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   160  of  4,059.    Elapsed: 0:13:57.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "161it [14:02,  5.19s/it]\u001b[A\n",
      "162it [14:07,  5.17s/it]\u001b[A\n",
      "163it [14:12,  5.16s/it]\u001b[A\n",
      "164it [14:17,  5.19s/it]\u001b[A\n",
      "165it [14:22,  5.21s/it]\u001b[A\n",
      "166it [14:28,  5.22s/it]\u001b[A\n",
      "167it [14:33,  5.20s/it]\u001b[A\n",
      "168it [14:38,  5.19s/it]\u001b[A\n",
      "169it [14:43,  5.18s/it]\u001b[A\n",
      "170it [14:48,  5.18s/it]\u001b[A\n",
      "171it [14:54,  5.18s/it]\u001b[A\n",
      "172it [14:59,  5.19s/it]\u001b[A\n",
      "173it [15:04,  5.28s/it]\u001b[A\n",
      "174it [15:10,  5.42s/it]\u001b[A\n",
      "175it [15:15,  5.43s/it]\u001b[A\n",
      "176it [15:21,  5.39s/it]\u001b[A\n",
      "177it [15:26,  5.38s/it]\u001b[A\n",
      "178it [15:31,  5.32s/it]\u001b[A\n",
      "179it [15:37,  5.31s/it]\u001b[A\n",
      "180it [15:42,  5.27s/it]\u001b[A\n",
      "181it [15:47,  5.27s/it]\u001b[A\n",
      "182it [15:52,  5.28s/it]\u001b[A\n",
      "183it [15:57,  5.25s/it]\u001b[A\n",
      "184it [16:03,  5.22s/it]\u001b[A\n",
      "185it [16:08,  5.20s/it]\u001b[A\n",
      "186it [16:13,  5.17s/it]\u001b[A\n",
      "187it [16:18,  5.16s/it]\u001b[A\n",
      "188it [16:23,  5.18s/it]\u001b[A\n",
      "189it [16:28,  5.20s/it]\u001b[A\n",
      "190it [16:34,  5.20s/it]\u001b[A\n",
      "191it [16:39,  5.21s/it]\u001b[A\n",
      "192it [16:44,  5.19s/it]\u001b[A\n",
      "193it [16:49,  5.23s/it]\u001b[A\n",
      "194it [16:55,  5.25s/it]\u001b[A\n",
      "195it [17:00,  5.27s/it]\u001b[A\n",
      "196it [17:05,  5.28s/it]\u001b[A\n",
      "197it [17:10,  5.24s/it]\u001b[A\n",
      "198it [17:16,  5.26s/it]\u001b[A\n",
      "199it [17:21,  5.22s/it]\u001b[A\n",
      "200it [17:26,  5.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of  4,059.    Elapsed: 0:17:27.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "201it [17:31,  5.17s/it]\u001b[A\n",
      "202it [17:36,  5.18s/it]\u001b[A\n",
      "203it [17:42,  5.23s/it]\u001b[A\n",
      "204it [17:47,  5.24s/it]\u001b[A\n",
      "205it [17:52,  5.21s/it]\u001b[A\n",
      "206it [17:57,  5.23s/it]\u001b[A\n",
      "207it [18:03,  5.23s/it]\u001b[A\n",
      "208it [18:08,  5.21s/it]\u001b[A\n",
      "209it [18:13,  5.22s/it]\u001b[A\n",
      "210it [18:18,  5.21s/it]\u001b[A\n",
      "211it [18:23,  5.22s/it]\u001b[A\n",
      "212it [18:29,  5.21s/it]\u001b[A\n",
      "213it [18:34,  5.22s/it]\u001b[A\n",
      "214it [18:39,  5.23s/it]\u001b[A\n",
      "215it [18:44,  5.23s/it]\u001b[A\n",
      "216it [18:50,  5.24s/it]\u001b[A\n",
      "217it [18:55,  5.27s/it]\u001b[A\n",
      "218it [19:00,  5.27s/it]\u001b[A\n",
      "219it [19:06,  5.27s/it]\u001b[A\n",
      "220it [19:11,  5.25s/it]\u001b[A\n",
      "221it [19:16,  5.21s/it]\u001b[A\n",
      "222it [19:21,  5.23s/it]\u001b[A\n",
      "223it [19:26,  5.25s/it]\u001b[A\n",
      "224it [19:32,  5.26s/it]\u001b[A\n",
      "225it [19:37,  5.26s/it]\u001b[A\n",
      "226it [19:42,  5.27s/it]\u001b[A\n",
      "227it [19:48,  5.41s/it]\u001b[A\n",
      "228it [19:53,  5.33s/it]\u001b[A\n",
      "229it [19:58,  5.30s/it]\u001b[A\n",
      "230it [20:04,  5.29s/it]\u001b[A\n",
      "231it [20:09,  5.30s/it]\u001b[A\n",
      "232it [20:14,  5.22s/it]\u001b[A\n",
      "233it [20:20,  5.36s/it]\u001b[A\n",
      "234it [20:25,  5.35s/it]\u001b[A\n",
      "235it [20:30,  5.31s/it]\u001b[A\n",
      "236it [20:35,  5.25s/it]\u001b[A\n",
      "237it [20:40,  5.23s/it]\u001b[A\n",
      "238it [20:46,  5.26s/it]\u001b[A\n",
      "239it [20:51,  5.26s/it]\u001b[A\n",
      "240it [20:56,  5.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   240  of  4,059.    Elapsed: 0:20:57.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "241it [21:02,  5.25s/it]\u001b[A\n",
      "242it [21:07,  5.23s/it]\u001b[A\n",
      "243it [21:12,  5.22s/it]\u001b[A\n",
      "244it [21:17,  5.25s/it]\u001b[A\n",
      "245it [21:22,  5.24s/it]\u001b[A\n",
      "246it [21:28,  5.24s/it]\u001b[A\n",
      "247it [21:33,  5.23s/it]\u001b[A\n",
      "248it [21:38,  5.25s/it]\u001b[A\n",
      "249it [21:43,  5.24s/it]\u001b[A\n",
      "250it [21:49,  5.23s/it]\u001b[A\n",
      "251it [21:54,  5.25s/it]\u001b[A\n",
      "252it [21:59,  5.28s/it]\u001b[A\n",
      "253it [22:05,  5.28s/it]\u001b[A\n",
      "254it [22:10,  5.26s/it]\u001b[A\n",
      "255it [22:15,  5.26s/it]\u001b[A\n",
      "256it [22:20,  5.27s/it]\u001b[A\n",
      "257it [22:26,  5.27s/it]\u001b[A\n",
      "258it [22:31,  5.27s/it]\u001b[A\n",
      "259it [22:36,  5.26s/it]\u001b[A\n",
      "260it [22:41,  5.27s/it]\u001b[A\n",
      "261it [22:47,  5.30s/it]\u001b[A\n",
      "262it [22:52,  5.28s/it]\u001b[A\n",
      "263it [22:57,  5.25s/it]\u001b[A\n",
      "264it [23:02,  5.25s/it]\u001b[A\n",
      "265it [23:08,  5.21s/it]\u001b[A\n",
      "266it [23:13,  5.22s/it]\u001b[A\n",
      "267it [23:18,  5.21s/it]\u001b[A\n",
      "268it [23:23,  5.21s/it]\u001b[A\n",
      "269it [23:28,  5.22s/it]\u001b[A\n",
      "270it [23:34,  5.21s/it]\u001b[A\n",
      "271it [23:39,  5.21s/it]\u001b[A\n",
      "272it [23:44,  5.20s/it]\u001b[A\n",
      "273it [23:49,  5.19s/it]\u001b[A\n",
      "274it [23:54,  5.18s/it]\u001b[A\n",
      "275it [24:00,  5.19s/it]\u001b[A\n",
      "276it [24:05,  5.19s/it]\u001b[A\n",
      "277it [24:10,  5.19s/it]\u001b[A\n",
      "278it [24:15,  5.20s/it]\u001b[A\n",
      "279it [24:20,  5.23s/it]\u001b[A\n",
      "280it [24:26,  5.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   280  of  4,059.    Elapsed: 0:24:26.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "281it [24:31,  5.25s/it]\u001b[A\n",
      "282it [24:36,  5.25s/it]\u001b[A\n",
      "283it [24:41,  5.24s/it]\u001b[A\n",
      "284it [24:47,  5.21s/it]\u001b[A\n",
      "285it [24:52,  5.20s/it]\u001b[A\n",
      "286it [24:57,  5.21s/it]\u001b[A\n",
      "287it [25:02,  5.22s/it]\u001b[A\n",
      "288it [25:07,  5.20s/it]\u001b[A\n",
      "289it [25:13,  5.20s/it]\u001b[A\n",
      "290it [25:18,  5.18s/it]\u001b[A\n",
      "291it [25:23,  5.17s/it]\u001b[A\n",
      "292it [25:28,  5.19s/it]\u001b[A\n",
      "293it [25:33,  5.18s/it]\u001b[A\n",
      "294it [25:39,  5.20s/it]\u001b[A\n",
      "295it [25:44,  5.19s/it]\u001b[A\n",
      "296it [25:49,  5.19s/it]\u001b[A\n",
      "297it [25:54,  5.22s/it]\u001b[A\n",
      "298it [25:59,  5.21s/it]\u001b[A\n",
      "299it [26:05,  5.25s/it]\u001b[A\n",
      "300it [26:10,  5.22s/it]\u001b[A\n",
      "301it [26:15,  5.21s/it]\u001b[A\n",
      "302it [26:20,  5.22s/it]\u001b[A\n",
      "303it [26:25,  5.20s/it]\u001b[A\n",
      "304it [26:31,  5.21s/it]\u001b[A\n",
      "305it [26:36,  5.17s/it]\u001b[A\n",
      "306it [26:41,  5.19s/it]\u001b[A\n",
      "307it [26:46,  5.18s/it]\u001b[A\n",
      "308it [26:51,  5.18s/it]\u001b[A\n",
      "309it [26:57,  5.21s/it]\u001b[A\n",
      "310it [27:02,  5.32s/it]\u001b[A\n",
      "311it [27:08,  5.44s/it]\u001b[A\n",
      "312it [27:14,  5.60s/it]\u001b[A\n",
      "313it [27:19,  5.52s/it]\u001b[A\n",
      "314it [27:24,  5.45s/it]\u001b[A\n",
      "315it [27:30,  5.38s/it]\u001b[A\n",
      "316it [27:35,  5.34s/it]\u001b[A\n",
      "317it [27:40,  5.30s/it]\u001b[A\n",
      "318it [27:45,  5.29s/it]\u001b[A\n",
      "319it [27:51,  5.28s/it]\u001b[A\n",
      "320it [27:56,  5.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   320  of  4,059.    Elapsed: 0:27:56.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "321it [28:01,  5.29s/it]\u001b[A\n",
      "322it [28:06,  5.27s/it]\u001b[A\n",
      "323it [28:12,  5.28s/it]\u001b[A\n",
      "324it [28:17,  5.30s/it]\u001b[A\n",
      "325it [28:22,  5.31s/it]\u001b[A\n",
      "326it [28:28,  5.31s/it]\u001b[A\n",
      "327it [28:33,  5.31s/it]\u001b[A\n",
      "328it [28:38,  5.30s/it]\u001b[A\n",
      "329it [28:44,  5.30s/it]\u001b[A\n",
      "330it [28:49,  5.28s/it]\u001b[A\n",
      "331it [28:54,  5.26s/it]\u001b[A\n",
      "332it [28:59,  5.27s/it]\u001b[A\n",
      "333it [29:05,  5.26s/it]\u001b[A\n",
      "334it [29:10,  5.29s/it]\u001b[A\n",
      "335it [29:15,  5.31s/it]\u001b[A\n",
      "336it [29:21,  5.30s/it]\u001b[A\n",
      "337it [29:26,  5.34s/it]\u001b[A\n",
      "338it [29:31,  5.31s/it]\u001b[A\n",
      "339it [29:37,  5.30s/it]\u001b[A\n",
      "340it [29:42,  5.36s/it]\u001b[A\n",
      "341it [29:48,  5.38s/it]\u001b[A\n",
      "342it [29:53,  5.36s/it]\u001b[A\n",
      "343it [29:58,  5.36s/it]\u001b[A\n",
      "344it [30:04,  5.48s/it]\u001b[A\n",
      "345it [30:10,  5.51s/it]\u001b[A\n",
      "346it [30:15,  5.44s/it]\u001b[A\n",
      "347it [30:20,  5.45s/it]\u001b[A\n",
      "348it [30:26,  5.41s/it]\u001b[A\n",
      "349it [30:31,  5.36s/it]\u001b[A\n",
      "350it [30:36,  5.36s/it]\u001b[A\n",
      "351it [30:42,  5.34s/it]\u001b[A\n",
      "352it [30:47,  5.30s/it]\u001b[A\n",
      "353it [30:52,  5.29s/it]\u001b[A\n",
      "354it [30:57,  5.29s/it]\u001b[A\n",
      "355it [31:03,  5.27s/it]\u001b[A\n",
      "356it [31:08,  5.24s/it]\u001b[A\n",
      "357it [31:13,  5.25s/it]\u001b[A\n",
      "358it [31:18,  5.30s/it]\u001b[A\n",
      "359it [31:24,  5.32s/it]\u001b[A\n",
      "360it [31:29,  5.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   360  of  4,059.    Elapsed: 0:31:30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "361it [31:35,  5.42s/it]\u001b[A\n",
      "362it [31:40,  5.43s/it]\u001b[A\n",
      "363it [31:45,  5.39s/it]\u001b[A\n",
      "364it [31:51,  5.43s/it]\u001b[A\n",
      "365it [31:56,  5.39s/it]\u001b[A\n",
      "366it [32:02,  5.34s/it]\u001b[A\n",
      "367it [32:07,  5.32s/it]\u001b[A\n",
      "368it [32:12,  5.31s/it]\u001b[A\n",
      "369it [32:17,  5.29s/it]\u001b[A\n",
      "370it [32:23,  5.31s/it]\u001b[A\n",
      "371it [32:28,  5.29s/it]\u001b[A\n",
      "372it [32:33,  5.31s/it]\u001b[A\n",
      "373it [32:39,  5.33s/it]\u001b[A\n",
      "374it [32:44,  5.33s/it]\u001b[A\n",
      "375it [32:49,  5.30s/it]\u001b[A\n",
      "376it [32:55,  5.31s/it]\u001b[A\n",
      "377it [33:00,  5.38s/it]\u001b[A\n",
      "378it [33:05,  5.33s/it]\u001b[A\n",
      "379it [33:11,  5.33s/it]\u001b[A\n",
      "380it [33:16,  5.30s/it]\u001b[A\n",
      "381it [33:21,  5.32s/it]\u001b[A\n",
      "382it [33:27,  5.33s/it]\u001b[A\n",
      "383it [33:32,  5.31s/it]\u001b[A\n",
      "384it [33:37,  5.29s/it]\u001b[A\n",
      "385it [33:42,  5.27s/it]\u001b[A\n",
      "386it [33:48,  5.27s/it]\u001b[A\n",
      "387it [33:53,  5.23s/it]\u001b[A\n",
      "388it [33:58,  5.22s/it]\u001b[A\n",
      "389it [34:03,  5.22s/it]\u001b[A\n",
      "390it [34:09,  5.32s/it]\u001b[A\n",
      "391it [34:14,  5.30s/it]\u001b[A\n",
      "392it [34:19,  5.28s/it]\u001b[A\n",
      "393it [34:24,  5.27s/it]\u001b[A\n",
      "394it [34:30,  5.24s/it]\u001b[A\n",
      "395it [34:35,  5.25s/it]\u001b[A\n",
      "396it [34:40,  5.31s/it]\u001b[A\n",
      "397it [34:46,  5.33s/it]\u001b[A\n",
      "398it [34:51,  5.36s/it]\u001b[A\n",
      "399it [34:57,  5.37s/it]\u001b[A\n",
      "400it [35:02,  5.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of  4,059.    Elapsed: 0:35:03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "401it [35:07,  5.35s/it]\u001b[A\n",
      "402it [35:12,  5.31s/it]\u001b[A\n",
      "403it [35:19,  5.53s/it]\u001b[A\n",
      "404it [35:24,  5.51s/it]\u001b[A\n",
      "405it [35:29,  5.44s/it]\u001b[A\n",
      "406it [35:35,  5.38s/it]\u001b[A\n",
      "407it [35:40,  5.36s/it]\u001b[A\n",
      "408it [35:45,  5.32s/it]\u001b[A\n",
      "409it [35:50,  5.32s/it]\u001b[A\n",
      "410it [35:56,  5.34s/it]\u001b[A\n",
      "411it [36:01,  5.37s/it]\u001b[A\n",
      "412it [36:07,  5.41s/it]\u001b[A\n",
      "413it [36:12,  5.41s/it]\u001b[A\n",
      "414it [36:18,  5.43s/it]\u001b[A\n",
      "415it [36:23,  5.38s/it]\u001b[A\n",
      "416it [36:28,  5.33s/it]\u001b[A\n",
      "417it [36:33,  5.34s/it]\u001b[A\n",
      "418it [36:39,  5.40s/it]\u001b[A\n",
      "419it [36:45,  5.46s/it]\u001b[A\n",
      "420it [36:50,  5.45s/it]\u001b[A\n",
      "421it [36:55,  5.40s/it]\u001b[A\n",
      "422it [37:01,  5.36s/it]\u001b[A\n",
      "423it [37:06,  5.32s/it]\u001b[A\n",
      "424it [37:11,  5.29s/it]\u001b[A\n",
      "425it [37:16,  5.25s/it]\u001b[A\n",
      "426it [37:21,  5.25s/it]\u001b[A\n",
      "427it [37:27,  5.26s/it]\u001b[A\n",
      "428it [37:32,  5.25s/it]\u001b[A\n",
      "429it [37:37,  5.24s/it]\u001b[A\n",
      "430it [37:42,  5.23s/it]\u001b[A\n",
      "431it [37:48,  5.22s/it]\u001b[A\n",
      "432it [37:53,  5.23s/it]\u001b[A\n",
      "433it [37:58,  5.23s/it]\u001b[A\n",
      "434it [38:03,  5.26s/it]\u001b[A\n",
      "435it [38:09,  5.26s/it]\u001b[A\n",
      "436it [38:14,  5.25s/it]\u001b[A\n",
      "437it [38:19,  5.26s/it]\u001b[A\n",
      "438it [38:24,  5.24s/it]\u001b[A\n",
      "439it [38:29,  5.22s/it]\u001b[A\n",
      "440it [38:35,  5.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   440  of  4,059.    Elapsed: 0:38:35.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "441it [38:40,  5.24s/it]\u001b[A\n",
      "442it [38:45,  5.31s/it]\u001b[A\n",
      "443it [38:51,  5.29s/it]\u001b[A\n",
      "444it [38:56,  5.27s/it]\u001b[A\n",
      "445it [39:01,  5.26s/it]\u001b[A\n",
      "446it [39:07,  5.28s/it]\u001b[A\n",
      "447it [39:12,  5.29s/it]\u001b[A\n",
      "448it [39:17,  5.28s/it]\u001b[A\n",
      "449it [39:22,  5.26s/it]\u001b[A\n",
      "450it [39:28,  5.29s/it]\u001b[A\n",
      "451it [39:33,  5.26s/it]\u001b[A\n",
      "452it [39:38,  5.26s/it]\u001b[A\n",
      "453it [39:43,  5.27s/it]\u001b[A\n",
      "454it [39:49,  5.25s/it]\u001b[A\n",
      "455it [39:54,  5.27s/it]\u001b[A\n",
      "456it [39:59,  5.27s/it]\u001b[A\n",
      "457it [40:04,  5.27s/it]\u001b[A\n",
      "458it [40:10,  5.25s/it]\u001b[A\n",
      "459it [40:15,  5.23s/it]\u001b[A\n",
      "460it [40:20,  5.26s/it]\u001b[A\n",
      "461it [40:25,  5.22s/it]\u001b[A\n",
      "462it [40:31,  5.27s/it]\u001b[A\n",
      "463it [40:36,  5.28s/it]\u001b[A\n",
      "464it [40:41,  5.30s/it]\u001b[A\n",
      "465it [40:47,  5.30s/it]\u001b[A\n",
      "466it [40:52,  5.26s/it]\u001b[A\n",
      "467it [40:57,  5.24s/it]\u001b[A\n",
      "468it [41:02,  5.24s/it]\u001b[A\n",
      "469it [41:07,  5.23s/it]\u001b[A\n",
      "470it [41:13,  5.23s/it]\u001b[A\n",
      "471it [41:18,  5.22s/it]\u001b[A\n",
      "472it [41:23,  5.21s/it]\u001b[A\n",
      "473it [41:28,  5.23s/it]\u001b[A\n",
      "474it [41:34,  5.23s/it]\u001b[A\n",
      "475it [41:39,  5.24s/it]\u001b[A\n",
      "476it [41:44,  5.26s/it]\u001b[A\n",
      "477it [41:49,  5.24s/it]\u001b[A\n",
      "478it [41:55,  5.22s/it]\u001b[A\n",
      "479it [42:00,  5.24s/it]\u001b[A\n",
      "480it [42:05,  5.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   480  of  4,059.    Elapsed: 0:42:06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "481it [42:10,  5.23s/it]\u001b[A\n",
      "482it [42:15,  5.23s/it]\u001b[A\n",
      "483it [42:21,  5.20s/it]\u001b[A\n",
      "484it [42:26,  5.21s/it]\u001b[A\n",
      "485it [42:31,  5.21s/it]\u001b[A\n",
      "486it [42:36,  5.22s/it]\u001b[A\n",
      "487it [42:42,  5.26s/it]\u001b[A\n",
      "488it [42:47,  5.30s/it]\u001b[A\n",
      "489it [42:52,  5.28s/it]\u001b[A\n",
      "490it [42:57,  5.27s/it]\u001b[A\n",
      "491it [43:03,  5.28s/it]\u001b[A\n",
      "492it [43:08,  5.25s/it]\u001b[A\n",
      "493it [43:13,  5.24s/it]\u001b[A\n",
      "494it [43:18,  5.22s/it]\u001b[A\n",
      "495it [43:24,  5.25s/it]\u001b[A\n",
      "496it [43:29,  5.26s/it]\u001b[A\n",
      "497it [43:35,  5.34s/it]\u001b[A\n",
      "498it [43:40,  5.35s/it]\u001b[A\n",
      "499it [43:45,  5.32s/it]\u001b[A\n",
      "500it [43:50,  5.29s/it]\u001b[A\n",
      "501it [43:56,  5.26s/it]\u001b[A\n",
      "502it [44:01,  5.26s/it]\u001b[A\n",
      "503it [44:06,  5.24s/it]\u001b[A\n",
      "504it [44:12,  5.35s/it]\u001b[A\n",
      "505it [44:17,  5.33s/it]\u001b[A\n",
      "506it [44:22,  5.34s/it]\u001b[A\n",
      "507it [44:28,  5.40s/it]\u001b[A\n",
      "508it [44:33,  5.38s/it]\u001b[A\n",
      "509it [44:38,  5.35s/it]\u001b[A\n",
      "510it [44:44,  5.36s/it]\u001b[A\n",
      "511it [44:49,  5.35s/it]\u001b[A\n",
      "512it [44:54,  5.35s/it]\u001b[A\n",
      "513it [45:00,  5.36s/it]\u001b[A\n",
      "514it [45:05,  5.37s/it]\u001b[A\n",
      "515it [45:11,  5.37s/it]\u001b[A\n",
      "516it [45:16,  5.42s/it]\u001b[A\n",
      "517it [45:21,  5.39s/it]\u001b[A\n",
      "518it [45:27,  5.39s/it]\u001b[A\n",
      "519it [45:32,  5.36s/it]\u001b[A\n",
      "520it [45:37,  5.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   520  of  4,059.    Elapsed: 0:45:38.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "521it [45:43,  5.29s/it]\u001b[A\n",
      "522it [45:48,  5.25s/it]\u001b[A\n",
      "523it [45:53,  5.26s/it]\u001b[A\n",
      "524it [45:58,  5.24s/it]\u001b[A\n",
      "525it [46:04,  5.26s/it]\u001b[A\n",
      "526it [46:09,  5.30s/it]\u001b[A\n",
      "527it [46:14,  5.26s/it]\u001b[A\n",
      "528it [46:19,  5.26s/it]\u001b[A\n",
      "529it [46:25,  5.27s/it]\u001b[A\n",
      "530it [46:30,  5.32s/it]\u001b[A\n",
      "531it [46:35,  5.34s/it]\u001b[A\n",
      "532it [46:41,  5.31s/it]\u001b[A\n",
      "533it [46:46,  5.37s/it]\u001b[A\n",
      "534it [46:51,  5.33s/it]\u001b[A\n",
      "535it [46:57,  5.35s/it]\u001b[A\n",
      "536it [47:02,  5.31s/it]\u001b[A\n",
      "537it [47:07,  5.26s/it]\u001b[A\n",
      "538it [47:12,  5.26s/it]\u001b[A\n",
      "539it [47:18,  5.29s/it]\u001b[A\n",
      "540it [47:23,  5.28s/it]\u001b[A\n",
      "541it [47:28,  5.29s/it]\u001b[A\n",
      "542it [47:34,  5.31s/it]\u001b[A\n",
      "543it [47:39,  5.34s/it]\u001b[A\n",
      "544it [47:45,  5.38s/it]\u001b[A\n",
      "545it [47:50,  5.35s/it]\u001b[A\n",
      "546it [47:55,  5.36s/it]\u001b[A\n",
      "547it [48:01,  5.39s/it]\u001b[A\n",
      "548it [48:06,  5.39s/it]\u001b[A\n",
      "549it [48:11,  5.36s/it]\u001b[A\n",
      "550it [48:17,  5.34s/it]\u001b[A\n",
      "551it [48:22,  5.36s/it]\u001b[A\n",
      "552it [48:27,  5.35s/it]\u001b[A\n",
      "553it [48:33,  5.34s/it]\u001b[A\n",
      "554it [48:38,  5.31s/it]\u001b[A\n",
      "555it [48:43,  5.32s/it]\u001b[A\n",
      "556it [48:49,  5.32s/it]\u001b[A\n",
      "557it [48:56,  5.27s/it]\u001b[A\n",
      "  0%|                                                                        | 0/4 [48:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2632\\3149191980.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     labels=b_labels)\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# The call to `model` always returns a tuple, so we need to pull the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1573\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1575\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1576\u001b[0m         )\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         )\n\u001b[0;32m   1033\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    615\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m                 )\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[1;32m--> 539\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m         )\n\u001b[0;32m    541\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "# torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in tqdm.tqdm(range(0, epochs)):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in tqdm.tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0]\n",
    "        b_input_mask = batch[1]\n",
    "        b_labels = batch[2]\n",
    "        \n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "#         print(b_input_ids)\n",
    "#         print(b_labels)\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.numpy()\n",
    "        label_ids = b_labels.numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/tokenizer_config.json',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/vocab.txt',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
